	데이터셋
패널‧변환 단계는 '설계→정규화→분포 안정화'라는 세 개의 고리로 엮였다. 먼저 03_build_panel.py는 전 레이어를 합친 원시 테이블을 complex_id × year_month 복합 키로 재구성해 월별 패널의 뼈대를 세웠다. 동일 단지‧월 중복은 0.9 %였는데, 가장 이른 항목을 남기고 제거한 뒤 총 61 138 행, 679 열이 남았다. 패널을 MultiIndex로 고정해 두면 이후 병합이나 롤링 집계에서 행정구역 변동이 있더라도 열(column)만 확장되기 때문에 "데이터 한 줄 = 특정 시점의 단지 상태"라는 해석이 유지된다. 이 시점에 단지 고정 속성(준공연도, 용적률, 학군 등)과 시간 가변 변수(거래가, 금리, 미분양 등)가 같은 레벨에 놓여 Hedonic과 Event-study를 동시에 적용할 수 있는 형태가 완성된다.

지역별 클러스터링을 통한 시장 세분화 과정에서 핵심적인 단계 중 하나는 지역별 주택시장의 이질성을 체계적으로 파악하는 것이었다. 전국 17개 시도의 특별공급 경쟁률, 일반공급 경쟁률, 지역 GDP 데이터를 활용하여 K-means 클러스터링을 수행한 결과, 명확한 시장 구조가 도출되었다. 클러스터 0은 일반 지역시장으로 14개 지역이 포함되어 평균 특별공급 경쟁률 1.42배, 일반공급 14.52배, GDP 852억원을 나타낸다. 클러스터 1은 초과수요 시장으로 2개 지역이 포함되어 평균 특별공급 경쟁률 59.12배, 일반공급 203.12배, GDP 2,720억원을 보인다. 클러스터 2는 경기 독립시장으로 1개 지역이 포함되어 특별공급 경쟁률 5.11배, 일반공급 20.6배, GDP 5,814억원을 기록한다. 이러한 클러스터링 결과는 Silhouette Score 0.713으로 매우 높은 품질을 보였으며, 각 지역의 시장 특성을 정량적으로 구분하는 기준으로 활용되었다. 특히 서울과 세종이 동일한 초과수요 클러스터로 분류된 것은 행정수도 이전 정책과 수도권 집중 현상이 유사한 시장 압력을 만들어내고 있음을 시사한다.

거래가격은 원본 분포의 왜도가 4.1로 심해 로그 선형화가 선행됐다. 02_feature_engineer.py에서 ln_price = log(price_per_m2)를 만들고, 변환 전·후 히스토그램을 저장해 값이 0 이하로 내려가는 구간이 없음을 확인했다. 이어 정규성-편향 진단을 위해 04_eda_qc.py가 샘플 5 000개로 Shapiro-Wilk 검정을 반복하면서 동시에 Box-Cox λ를 계산했다. price_per_m2는 λ ≈ 0.36, 즉 로그에 가까운 형태로 수렴했고 ln_price 자체는 λ ≈ 6으로 과도한 팽창을 보여 "로그→λ≈0" 구간의 재조정 필요성이 드러났다.

실제 모델 학습용 변환은 06_transform_dist.py에서 수행했다. Box-Cox는 양수만 허용하기 때문에 0 또는 음수가 섞인 계량·거시 변수까지 포괄하려면 범위가 자유로운 Yeo–Johnson이 적합하다. 스크립트는 모든 수치 변수 중 |skew| > 1인 항목을 골라 Y-J를 적용하고, 변환 값의 상·하위 1 %를 절단(Winsorize)해 극단치를 눌렀다. 가격 계열의 경우 price_per_m2는 yj_price_per_m2로, ln_price는 yj_ln_price로 파생됐고 각 변수의 λ와 절단 구간을 메타데이터에 기록해 재현성을 확보했다. 변환 후 두 변수의 왜도는 각각 0.12와 –0.05로 크게 완화돼 Shapiro p-값(≈0.19, 0.44)이 귀무가설을 기각하지 못하는 수준으로 올라갔다. 완성된 테이블 panel_model_transformed.parquet는 원본 열을 보존한 채 "yj_"와 "_w"(Winsorized) 접미사를 추가했으며, 향후 ML 베이스라인이나 Causal-DiD 실험에서도 같은 전처리를 재사용할 수 있게 했다.

클러스터링 기반 지역 더미 변수 생성 과정에서 특히 중요한 혁신은 클러스터링 결과를 활용한 지역 더미 변수의 생성이었다. 기존의 단순한 시도별 더미 변수 대신, K-means 클러스터링으로 도출된 3개 클러스터를 기반으로 한 더미 변수를 생성하여 모델의 설명력을 향상시켰다. 이는 지역 간 경제적·사회적 유사성을 반영한 보다 정교한 지역 구분을 가능하게 했다.

이러한 패널 구성-로그 선형화-Box-Cox/ Yeo–Johnson 체인은 단위 근 제거·정규성 확보를 통해 Hedonic OLS의 가정 위반을 최소화하고, 이벤트 스터디에서 τ-스케일 곡선의 잔차를 안정화하며, 시계열·딥러닝 모델에 바로 투입해도 학습이 가능한 범용 입력 포맷을 제공한다. 다음 절에서는 이 정제된 데이터를 바탕으로 HC3 표준오차를 갖춘 Hedonic OLS와 입주-전후 이벤트 곡선을 어떻게 결합했는지 설명한다.

전처리 파이프라인 개요에서 교수님 강의(Unit 3)에서 제시된 '데이터 정제·정규화' 흐름을 실무 파이프라인으로 옮긴 결과는 다음과 같다. 첫 번째 단계인 문자 인코딩 통일은 script/01_clean_merge.py에서 encodings = ['cp949','euc-kr','utf-8','utf-8-sig']를 통한 다중 시도 로드로 구현되었다. 두 번째 단계인 결측·이상치 처리는 script/02_feature_engineer.py에서 df[col] = pd.to_numeric(df[col], errors='coerce')와 fillna(method='ffill')로 처리되었다. 세 번째 단계인 단위·천단위 제거는 script/01_clean_merge.py에서 price = price.str.replace(',', '')와 astype(int)로 구현되었다. 네 번째 단계인 Box-Cox / Yeo–Johnson 변환은 script/06_transform_dist.py에서 yj = PowerTransformer(method='yeo-johnson')로 적용되었다. 다섯 번째 단계인 Winsorize(±1 %)는 같은 06_transform_dist.py에서 quantiles = df[col].quantile([.01,.99])로 처리되었다. 여섯 번째 단계인 클러스터링 기반 지역 분류는 analysis/clustering_analysis.py에서 KMeans(n_clusters=3, random_state=42)로 수행되었다.

클러스터링 품질 지표로는 Silhouette Score 0.713으로 매우 양호한 결과를 보였고, Calinski-Harabasz Index는 높은 클러스터 분리도를, Davies-Bouldin Index는 낮은 클러스터 내 분산을 나타냈다. 위 절차는 output/panel_model_transformed.parquet에 메타데이터(λ, 절단 구간, 클러스터 라벨)와 함께 저장되어 언제든 재현 가능한 구조를 갖춘다. 특히 클러스터링 결과는 analysis/result/ 디렉토리에 별도로 저장되어 후속 분석에서 재사용할 수 있도록 구성되었다.